{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimators란\n",
    "----\n",
    "텐서플로우 프로그래밍을 단순화시키기 위한 high-level API. 다음 기능들을 수행한다:\n",
    "\n",
    "- training\n",
    "- evaluation\n",
    "- prediction\n",
    "\n",
    "pre-made된 Estimators를 쓸 수도 있고, 직접 Estimators를 만들어 쓸 수도 있다. 그러나 어느쪽이든 공통적으로 <b>tf.estimator.Estimator</b> class를 기반으로 한다 \n",
    "\n",
    "<p>\n",
    "    \n",
    "* 참조1 : https://www.tensorflow.org/guide/estimators\n",
    "* 참조2 : https://www.tensorflow.org/tutorials/estimators/linear\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "\n",
    "## Estimators의 장점\n",
    "----\n",
    "\n",
    "* 로컬호스트 또는 분산된 멀티서버 환경에서 모델을 수정하지 않고도 Estimator 기반의 모델을 실행시킬 수 있다 (CPU, GPU, TPU 모두)\n",
    "* 모델 개발자들이 쉽게 모델을 공유하며 만들 수 있다\n",
    "* 최신 모델을 high-level의 직관적인 코드로 개발할 수 있다. 즉, low-level 텐서플로우 API보다 더 쉽게 모델을 만들 수 있다.\n",
    "* tf.keras.layers에 내장되어 있어 커스터마이징이 쉽다\n",
    "* 자신만의 그래프를 build할 수 있다\n",
    "* Estimator는 안전하게 분산 반복 학습을 할 수 있으며 다음 요소들을 제어한다:\n",
    "\n",
    "    - build the graph\n",
    "    - initialize variables\n",
    "    - load data\n",
    "    - handle exceptions\n",
    "    - create checkpoint files and recover from failures\n",
    "    - save summaries for TensorBoard\n",
    "\n",
    "\n",
    "* Estimator로 어플리케이션을 만들 땐 반드시 데이터 입력 파이프라인을 모델로부터 분리해야 한다. 그렇게 해야 다른 데이터셋에 대해서도 쉽게 모델을 실행할 수 있기 때문이다\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "\n",
    "## Pre-made Estimators란\n",
    "----\n",
    "* pre-made Estimator는 tf.Graph와 tf.Session 객체를 생성 및 관리해준다. (즉 직접 그래프나 세션을 만드느라 고생할 필요가 없다) \n",
    "* pre-made Estimator는 서로 다른 모델에 대해서도 최소한의 코드만 수정하면 실행할 수 있도록 해준다. \n",
    "    * 예시) tf.estimator.DNNClassifier는 dense, feed-forward 신경망에 기반한 classification 모델을 학습시켜주는 클래스이다.\n",
    "\n",
    "\n",
    "* pre-made Estimators의 장점\n",
    "    * 그래프의 서로 다른 부분들 실행할 때 어느 부분을 실행할 지 결정하는데에 도움을 준다\n",
    "    * 단일 서버 또는 클러스터 모두에서 사용할 수 있다\n",
    "    * Best practices for event (summary) writing and universally useful summaries.\n",
    "\n",
    "\n",
    "* pre-made Estimator를 사용하지 않는다면 앞서 말한 기능들을 직접 구현해야 한다\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "\n",
    "## Pre-made Estimators 구조\n",
    "---\n",
    "#### 1. Write one or more dataset importing functions:\n",
    "    \n",
    "* 예시로, 학습셋을 import하는 function과 테스트셋을 import하는 function을 만들 수 있다. 데이터셋을 임포트하는 함수는 반드시 다음의 두 객체를 반환해야 한다\n",
    "        \n",
    "    * 키가 feature names이고 값이 (feature data를 포함하는) Tensors인 <b>딕셔너리</b>\n",
    "    * 하나 이상의 레이블을 포함하는 <b>Tensors</b>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_fn style 1\n",
    "def input_fn(dataset):\n",
    "    # manipulate dataset, extracting the feature dict and the label\n",
    "    # (생략)\n",
    "    return feature_dict, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_fn style 2\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x = {\"f1\": some_numpy_array},      # Input features\n",
    "      y = some_numpy_array,          # true labels\n",
    "      batch_size=some_value,\n",
    "      num_epochs=None,                             # Supply unlimited epochs of data\n",
    "      shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Define the feature columns:\n",
    "\n",
    "* 각각의 tf.feature_column들은 feature의 이름, 타입, 입력 전처리 과정들을 구분한다. \n",
    "    * 예시로, 아래의 코드는 integer 또는 float 값을 갖는 3개의 feature column들을 생성한다. 처음 2개 feature column들은 feature들의 이름과 타입을 구분한다. 세 번째 feature column은 raw 데이터의 스케일을 지정하기 위한 람다식을 지정한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define three numeric feature columns.\n",
    "population = tf.feature_column.numeric_column('population')\n",
    "crime_rate = tf.feature_column.numeric_column('crime_rate')\n",
    "median_education = tf.feature_column.numeric_column('median_education',\n",
    "                                                    normalizer_fn=lambda x: x - global_education_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Instantiate the relevant pre-made Estimator:\n",
    "* For example, here's a sample instantiation of a pre-made Estimator named LinearClassifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an estimator, passing the feature columns.\n",
    "estimator = tf.estimator.LinearClassifier(\n",
    "    feature_columns=[population, crime_rate, median_education])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Call a training, evaluation, or inference method:\n",
    "\n",
    "* For example, all Estimators provide a train method, which trains a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `input_fn` is the function created in Step 1\n",
    "estimator.train(input_fn=my_training_set, steps=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "\n",
    "## Tutorial\n",
    "----\n",
    "\n",
    "tf.estimator에 내장된 Estimator를 사용해보자\n",
    "\n",
    "* 참조 : https://jhui.github.io/2017/03/14/TensorFlow-Estimator/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhkdn9192/venv/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the feature columns\n",
    "\n",
    "In our example, we define a single feature with name f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_feature = tf.feature_column.numeric_column('f1')\n",
    "\n",
    "# We can use more than one feature. We can even pre normalize the feature with a lambda function:\n",
    "# n_room = tf.feature_column.numeric_column('n_rooms')\n",
    "# sqfeet = tf.feature_column.numeric_column('square_feet', normalizer_fn='lambda a: a - global_size')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### input_fn\n",
    "\n",
    "To import data to the Estimator later, we prepare an input_fn for training, testing and prediction respectively. In each input_fn, we provide all input features and values in x and the true labels in y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x = {\"f1\": np.array([1., 2., 3., 4.])},      # Input features\n",
    "      y = np.array([1.5, 3.5, 5.5, 7.5]),          # true labels\n",
    "      batch_size=2,\n",
    "      num_epochs=None,                             # Supply unlimited epochs of data\n",
    "      shuffle=True)\n",
    "\n",
    "# Testing\n",
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x = {\"f1\": np.array([5., 6., 7.])},\n",
    "      y = np.array([9.5, 11.5, 13.5]),\n",
    "      num_epochs=1,\n",
    "      shuffle=False)\n",
    "\n",
    "# Prediction\n",
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"f1\": np.array([8., 9.])},\n",
    "      num_epochs=1,\n",
    "      shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_fn in general returns a tuple <b>feature_dict</b> and <b>label</b>. feature_dict is a dict containing the feature names and the feature data, and label contains the true values for all the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/dhkdn9192/venv/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /Users/dhkdn9192/venv/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "({'f1': <tf.Tensor 'random_shuffle_queue_DequeueMany:1' shape=(2,) dtype=float64>}, <tf.Tensor 'random_shuffle_queue_DequeueMany:2' shape=(2,) dtype=float64>)\n"
     ]
    }
   ],
   "source": [
    "print(train_input_fn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': <tf.Tensor 'fifo_queue_DequeueUpTo:1' shape=(?,) dtype=float64>}\n"
     ]
    }
   ],
   "source": [
    "print(predict_input_fn())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use a pre-built estimator\n",
    "\n",
    "* TensorFlow comes with many built-in estimator:\n",
    "\n",
    "    * DNNClassifier\n",
    "    * DNNLinearCombinedClassifier\n",
    "    * DNNLinearCombinedRegressor\n",
    "    * DNNRegressor\n",
    "    * LinearClassifier\n",
    "    * LinearRegressor\n",
    "\n",
    "\n",
    "* To demonstrate the idea, we use the LinearRegressor to model:\n",
    "\n",
    "    * y=Wx+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11d67bcc0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "regressor = tf.estimator.LinearRegressor(\n",
    "    feature_columns=[x_feature],\n",
    "    model_dir='./output'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training, validation and testing\n",
    "\n",
    "Then we run the training, validation and testing with the corresponding input_fn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./output/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /Users/dhkdn9192/venv/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into ./output/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.7722535e-10, step = 5001\n",
      "INFO:tensorflow:global_step/sec: 999.451\n",
      "INFO:tensorflow:loss = 4.5474735e-11, step = 5101 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 1363.61\n",
      "INFO:tensorflow:loss = 4.0472514e-11, step = 5201 (0.074 sec)\n",
      "INFO:tensorflow:global_step/sec: 1248.99\n",
      "INFO:tensorflow:loss = 6.895107e-11, step = 5301 (0.080 sec)\n",
      "INFO:tensorflow:global_step/sec: 1316.31\n",
      "INFO:tensorflow:loss = 4.240519e-11, step = 5401 (0.075 sec)\n",
      "INFO:tensorflow:global_step/sec: 1256.49\n",
      "INFO:tensorflow:loss = 4.5474735e-11, step = 5501 (0.080 sec)\n",
      "INFO:tensorflow:global_step/sec: 1288.77\n",
      "INFO:tensorflow:loss = 3.890932e-11, step = 5601 (0.078 sec)\n",
      "INFO:tensorflow:global_step/sec: 1348.06\n",
      "INFO:tensorflow:loss = 3.1960212e-11, step = 5701 (0.074 sec)\n",
      "INFO:tensorflow:global_step/sec: 1409.28\n",
      "INFO:tensorflow:loss = 1.546141e-11, step = 5801 (0.071 sec)\n",
      "INFO:tensorflow:global_step/sec: 1456.26\n",
      "INFO:tensorflow:loss = 4.092726e-12, step = 5901 (0.068 sec)\n",
      "INFO:tensorflow:global_step/sec: 1465.96\n",
      "INFO:tensorflow:loss = 1.4836132e-11, step = 6001 (0.069 sec)\n",
      "INFO:tensorflow:global_step/sec: 1484.83\n",
      "INFO:tensorflow:loss = 2.1501023e-11, step = 6101 (0.067 sec)\n",
      "INFO:tensorflow:global_step/sec: 1479.51\n",
      "INFO:tensorflow:loss = 4.5474735e-13, step = 6201 (0.069 sec)\n",
      "INFO:tensorflow:global_step/sec: 1298.88\n",
      "INFO:tensorflow:loss = 1.5702994e-11, step = 6301 (0.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 1362.44\n",
      "INFO:tensorflow:loss = 1.2050805e-11, step = 6401 (0.073 sec)\n",
      "INFO:tensorflow:global_step/sec: 1189.97\n",
      "INFO:tensorflow:loss = 1.2562396e-11, step = 6501 (0.084 sec)\n",
      "INFO:tensorflow:global_step/sec: 1405.94\n",
      "INFO:tensorflow:loss = 1.2050805e-11, step = 6601 (0.071 sec)\n",
      "INFO:tensorflow:global_step/sec: 1431\n",
      "INFO:tensorflow:loss = 1.2050805e-11, step = 6701 (0.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 1326.03\n",
      "INFO:tensorflow:loss = 1.1269208e-11, step = 6801 (0.076 sec)\n",
      "INFO:tensorflow:global_step/sec: 1358.38\n",
      "INFO:tensorflow:loss = 1.546141e-11, step = 6901 (0.074 sec)\n",
      "INFO:tensorflow:global_step/sec: 1356.04\n",
      "INFO:tensorflow:loss = 1.2562396e-11, step = 7001 (0.074 sec)\n",
      "INFO:tensorflow:global_step/sec: 1429.88\n",
      "INFO:tensorflow:loss = 1.2050805e-11, step = 7101 (0.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 1451.63\n",
      "INFO:tensorflow:loss = 1.1652901e-11, step = 7201 (0.069 sec)\n",
      "INFO:tensorflow:global_step/sec: 1402.19\n",
      "INFO:tensorflow:loss = 1.2050805e-11, step = 7301 (0.072 sec)\n",
      "INFO:tensorflow:global_step/sec: 1291.06\n",
      "INFO:tensorflow:loss = 1.2050805e-11, step = 7401 (0.077 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7500 into ./output/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.2050805e-11.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearRegressor at 0x11d65beb8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "regressor.train(input_fn=train_input_fn, steps=2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-02-21-05:23:46\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./output/model.ckpt-7500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-02-21-05:23:46\n",
      "INFO:tensorflow:Saving dict for global step 7500: average_loss = 6.699944e-11, global_step = 7500, label/mean = 11.5, loss = 2.0099833e-10, prediction/mean = 11.499992\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 7500: ./output/model.ckpt-7500\n",
      ">> average_loss : 6.699944071764108e-11\n"
     ]
    }
   ],
   "source": [
    "# evaluate(test)\n",
    "average_loss = regressor.evaluate(input_fn=test_input_fn)[\"average_loss\"]\n",
    "print(f'>> average_loss : {average_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./output/model.ckpt-7500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      ">> predictions : [{'predictions': array([15.499988], dtype=float32)}, {'predictions': array([17.499985], dtype=float32)}]\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "predictions = list(regressor.predict(input_fn=predict_input_fn))\n",
    "print(f'>> predictions : {predictions}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "\n",
    "## Creating Estimators from Keras models\n",
    "---\n",
    "이미 만들어진 Keras 모델을 Estimators로 변환할 수 있다. <b>tf.keras.estimator.model_to_estimator</b>를 이용한다\n",
    "\n",
    "* 참조 : http://marubon-ds.blogspot.com/2018/01/how-to-convert-keras-model-to.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Activation, Flatten\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load mnist data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-9ce68095cbf9>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/dhkdn9192/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/dhkdn9192/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/dhkdn9192/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/dhkdn9192/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/dhkdn9192/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# load mnist data for training\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data.shape : (300, 784)\n",
      "train_labels.shape : (300, 10)\n"
     ]
    }
   ],
   "source": [
    "train_data = mnist.train.images[:300]\n",
    "train_labels = mnist.train.labels[:300]\n",
    "\n",
    "print(f'train_data.shape : {train_data.shape}')\n",
    "print(f'train_labels.shape : {train_labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 109,386\n",
      "Trainable params: 109,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# set model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=784))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10, input_dim=8))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Keras model to Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/vn/ywztlbsn63jfty01rdy5gssr0000gn/T/tmp8i08za4k\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/vn/ywztlbsn63jfty01rdy5gssr0000gn/T/tmp8i08za4k', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11f1b9b38>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "estimator_model = keras.estimator.model_to_estimator(keras_model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x12b1d2390>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={model.input_names[0]: train_data.astype(np.float32)},\n",
    "    y=train_labels.astype(np.float32),\n",
    "    num_epochs=None,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='/var/folders/vn/ywztlbsn63jfty01rdy5gssr0000gn/T/tmp8i08za4k/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
      "INFO:tensorflow:Warm-starting from: ('/var/folders/vn/ywztlbsn63jfty01rdy5gssr0000gn/T/tmp8i08za4k/keras/keras_model.ckpt',)\n",
      "INFO:tensorflow:Warm-starting variable: dense/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense_1/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense_1/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense_2/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense_2/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: SGD/iterations; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: SGD/lr; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: SGD/momentum; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: SGD/decay; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/SGD/Variable; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/SGD/Variable_1; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/SGD/Variable_2; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/SGD/Variable_3; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/SGD/Variable_4; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/SGD/Variable_5; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/vn/ywztlbsn63jfty01rdy5gssr0000gn/T/tmp8i08za4k/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.336968, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 50 into /var/folders/vn/ywztlbsn63jfty01rdy5gssr0000gn/T/tmp8i08za4k/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.6971831.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x12b1d2390>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator_model.train(input_fn=train_input_fn, steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### keras.application의 기본 모델에 대한 converting 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a Keras inception v3 model.\n",
    "keras_inception_v3 = tf.keras.applications.inception_v3.InceptionV3(weights=None)\n",
    "keras_inception_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model with the optimizer, loss, and metrics you'd like to train with.\n",
    "keras_inception_v3.compile(optimizer=tf.keras.optimizers.SGD(lr=0.0001, momentum=0.9),\n",
    "                          loss='categorical_crossentropy',\n",
    "                          metric='accuracy')\n",
    "keras_inception_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Estimator from the compiled Keras model. Note the initial model\n",
    "# state of the keras model is preserved in the created Estimator.\n",
    "est_inception_v3 = tf.keras.estimator.model_to_estimator(keras_model=keras_inception_v3)\n",
    "est_inception_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once we have the input name(s), we can create the input function, for example,\n",
    "# for input(s) in the format of numpy ndarray:\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={keras_inception_v3.input_names[0]: train_data},\n",
    "    y=train_labels,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To train, we call Estimator's train function:\n",
    "est_inception_v3.train(input_fn=train_input_fn, steps=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
